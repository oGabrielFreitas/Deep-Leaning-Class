{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Irisdataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6rPy33sZE9w"
      },
      "source": [
        "# Baixando o Dataset\n",
        "\n",
        "O código abaixo baixa o arquivo `Iris.csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bgSGK47MVmj",
        "outputId": "96552fb3-9127-46f2-baf7-8d91b03bc0b9"
      },
      "source": [
        "!gdown --id '1d3NbjXro_BfnYpFm66ETBfe7ubAZPAoL'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1d3NbjXro_BfnYpFm66ETBfe7ubAZPAoL\n",
            "To: /content/Iris.csv\n",
            "\r  0% 0.00/5.11k [00:00<?, ?B/s]\r100% 5.11k/5.11k [00:00<00:00, 4.46MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm-9AefiZMJc"
      },
      "source": [
        "# Importação do PyTorch\n",
        "\n",
        "A seguir importamos a biblioteca PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbTDh5qsMlrr"
      },
      "source": [
        "#Aqui importamos o módulo do PyTorch\n",
        "\n",
        "import torch\n",
        "\n",
        "# Em seguida ajustamos para suprimir a\n",
        "# notação científica na hora de imprimir\n",
        "# os tensores\n",
        "\n",
        "torch.set_printoptions(precision=2,sci_mode=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAJFUjETZdF0"
      },
      "source": [
        "# Leitura dos dados\n",
        "\n",
        "Nas linhas seguintes fazemos a leitura dos dados do arquivo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3flfP46QMitf"
      },
      "source": [
        "# Abre o arquivo e faz uma leitura\n",
        "# das suas linhas\n",
        "\n",
        "f = open('Iris.csv', 'r')\n",
        "lines = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi-k1iZGMqVp"
      },
      "source": [
        "# 4 entradas\n",
        "X = torch.zeros(len(lines)-1,4)\n",
        "\n",
        "# 3 saídas desejadas (one-hot)\n",
        "Y = torch.zeros(len(lines)-1,3)\n",
        "\n",
        "# Teremos 3 categorias. O vetor abaixo lista as strings\n",
        "# que representam as categorias possíveis\n",
        "cats = ['Iris-setosa','Iris-versicolor','Iris-virginica']\n",
        "\n",
        "# Para cada linha do arquivo, exceto\n",
        "# a primeira linha que é o cabeçalho\n",
        "for i, line in enumerate(lines[1:]):\n",
        "\n",
        "  # Aqui decodificamos a linha para transformar\n",
        "  # de binário para caracteres ascii, e descartamos\n",
        "  # o último caractere que representa uma nova linha\n",
        "  s = line[:-1]\n",
        "\n",
        "  # Aqui separamos os dados por vírgulas,\n",
        "  # descartando o primeiro valor que é o id\n",
        "  # pois usaremos i do laço como id.\n",
        "  _,sl,sw,pl,pw,sp = s.split(',')\n",
        "\n",
        "  # Transformamos as strings que representam\n",
        "  # as dimensões de sépala e pétala para ponto\n",
        "  # flutuante.\n",
        "  sl = float(sl)\n",
        "  sw = float(sw)\n",
        "  pl = float(pl)\n",
        "  pw = float(pw)\n",
        "  \n",
        "  # Aqui populamos as matrizes X e Y com os dados\n",
        "  # coletados.\n",
        "  X[i,:] = torch.tensor([sl,sw,pl,pw])\n",
        "  Y[i,:] = torch.tensor([1 if sp == cat else 0 for cat in cats])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht6wk1vFZnpR"
      },
      "source": [
        "# Embaralhamento e Separação de Dados de Validação\n",
        "\n",
        "A seguir embaralhamos os pares de entradas e respectivas saídas desejadas, separando uma parte das amostras para validação do resultado do treinamento da rede neural."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6Wb7KcqMygj"
      },
      "source": [
        "import random\n",
        "\n",
        "# Aqui criamos uma lista de índices\n",
        "# embaralhados\n",
        "indexes = list(range(150))\n",
        "random.shuffle(indexes)\n",
        "\n",
        "# Essa variável T indica quantas amostras\n",
        "# serão usadas para treinamento. As demais\n",
        "# serão usadas para validação\n",
        "T = 140\n",
        "\n",
        "# Aqui preparamos as matrizes dos pares\n",
        "# de dados de treinamento e validação.\n",
        "Xt = torch.zeros(T,4)\n",
        "Yt = torch.zeros(T,3)\n",
        "Xv = torch.zeros(150-T,4)\n",
        "Yv = torch.zeros(150-T,3)\n",
        "\n",
        "# Aqui preenchemos as matrizes com os\n",
        "# respectivos valores\n",
        "for i in range(0,T):\n",
        "  Xt[i,:] = X[indexes[i],:]\n",
        "  Yt[i,:] = Y[indexes[i],:]\n",
        "for i in range(0,150-T):\n",
        "  Xv[i,:] = X[indexes[T+i],:]\n",
        "  Yv[i,:] = Y[indexes[T+i],:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BUIJdRqZzl6"
      },
      "source": [
        "# Módulos auxiliares\n",
        "\n",
        "Esses submódulos do PyTorch facilitam a construção de redes neurais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IxeNX_zM5cu"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NkQg8B1Z7Rg"
      },
      "source": [
        "# Definição da Arquitetura\n",
        "\n",
        "No código a seguir criamos a rede neural como uma classe que deriva de `nn.Module`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKjwEubHNLgb"
      },
      "source": [
        "# Essa é a classe da rede neural\n",
        "\n",
        "class Perceptron(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    # Chamamos o construtor da classe\n",
        "    # mãe (nn.Module)\n",
        "    \n",
        "    super(Perceptron, self).__init__()\n",
        "\n",
        "    # Criamos os objetos que implementam\n",
        "    # a parte referente à combinação linear\n",
        "    # (pesos sinapticos e biases)\n",
        "\n",
        "    self.c1 = nn.Linear(4, 8)\n",
        "    self.c2 = nn.Linear(8, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Aqui calculamos a parte\n",
        "    # linear da primeira\n",
        "    # camada\n",
        "\n",
        "    s1 = self.c1(x)\n",
        "\n",
        "    # Aplicamos a função de\n",
        "    # ativação sigmoide\n",
        "\n",
        "    z1 = torch.sigmoid(s1)\n",
        "\n",
        "    # E calculamos a parte\n",
        "    # linear da segunda e\n",
        "    # última camada.\n",
        "    s2 = self.c2(z1)\n",
        "\n",
        "    # Retornamos assim mesmo,\n",
        "    # sem ativação, já que a\n",
        "    # função softmax é implementada\n",
        "    # diretamente na hora de\n",
        "    # calcular o custo\n",
        "    \n",
        "    return s2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs_L2lZgPFo9",
        "outputId": "6a78aae4-1e68-4fa5-97dc-ad5f47310650"
      },
      "source": [
        "# Aqui instanciamos o objeto\n",
        "\n",
        "p = Perceptron()\n",
        "print(p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perceptron(\n",
            "  (c1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (c2): Linear(in_features=8, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnEOZd9pPXhv",
        "outputId": "a079eb58-fa5c-43d3-9773-18dc97509db0"
      },
      "source": [
        "# Esse método herdado da classe mãe\n",
        "# mostra todos os parâmetros, que\n",
        "# nesse caso são os pesos e biases\n",
        "# de todas as camadas.\n",
        "\n",
        "list(p.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.15, -0.15,  0.12, -0.13],\n",
              "         [-0.01,  0.27, -0.06, -0.02],\n",
              "         [ 0.11, -0.22,  0.48,  0.43],\n",
              "         [ 0.18, -0.14,  0.27,  0.05],\n",
              "         [-0.24,  0.47,  0.49,  0.13],\n",
              "         [-0.26, -0.06,  0.46,  0.08],\n",
              "         [ 0.20,  0.19, -0.48,  0.24],\n",
              "         [-0.27,  0.09, -0.36,  0.09]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.10,  0.27, -0.48, -0.01,  0.45,  0.14,  0.01, -0.23],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.29,  0.02, -0.11,  0.31, -0.01, -0.18, -0.02, -0.30],\n",
              "         [-0.15, -0.28, -0.02,  0.12,  0.30, -0.19,  0.08,  0.25],\n",
              "         [-0.02, -0.15,  0.31,  0.12,  0.03, -0.27,  0.20, -0.28]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.26,  0.29, -0.17], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EErcOnN4blEy"
      },
      "source": [
        "# Função de Perda e Treinamento\n",
        "\n",
        "No código a seguir mostramos como pode ser aplicada uma função de perda e realizado o treinamento da rede neural."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5qRvua1PpGA",
        "outputId": "eb51b770-62a2-4427-ab0e-917c0dfa4ed2"
      },
      "source": [
        "# Aqui criamos uma entrada arbitrária\n",
        "\n",
        "x = torch.tensor([[1.0,2.0,3.0,4.0]])\n",
        "\n",
        "# Calculamos a saída da rede neural\n",
        "# mesmo que ainda usando pesos e biases\n",
        "# aleatórios\n",
        "\n",
        "y = p(x)\n",
        "\n",
        "# E criamos uma saída desejada (arbitrária,\n",
        "# só para demonstração)\n",
        "y_hat = torch.tensor([[0.0, 1.0, 0.0]])\n",
        "\n",
        "# Essa linha de código cria o objeto\n",
        "# que implementa a função de perda do\n",
        "# tipo Entropia Cruzada\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# Aqui usamos o objeto criado para calcular\n",
        "# a função de perda aplicada à saída calculada\n",
        "# e saída desejada.\n",
        "\n",
        "e = loss(y, y_hat.argmax(dim=1))\n",
        "print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.86, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAMU7f8rRQ84"
      },
      "source": [
        "# Esse erro acima pode ser propagado\n",
        "# para os parâmetros, calculando as\n",
        "# derivadas parciais do erro para\n",
        "# cada respectivo parâmetro (gradiente\n",
        "# do erro)\n",
        "\n",
        "# Aqui zeramos o gradiente (zeramos\n",
        "# as derivadas parciais do erro em\n",
        "# relação a cada um dos parâmetros\n",
        "# da rede neural)\n",
        "\n",
        "p.zero_grad()\n",
        "\n",
        "# Em seguida propagammos o gradiente\n",
        "# do erro de trás para frente, usando\n",
        "# a regra da cadeia (isso calcula as\n",
        "# derivadas parciais do erro para cada\n",
        "# um dos parâmetros da rede neural)\n",
        "\n",
        "e.backward()\n",
        "\n",
        "# No laço abaixo aplicamos uma pequena\n",
        "# correção de um passo de tamanho 0.1\n",
        "# no sentido contrário ao do gradiente\n",
        "# de cada parâmetro (descida do gradiente)\n",
        "\n",
        "for param in p.parameters():\n",
        "  param.data -= 0.1*param.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE7WLQaWR0NL",
        "outputId": "150c01a5-94e8-4cea-bf46-2ea425b4e522"
      },
      "source": [
        "# O código a seguir combina todas essas\n",
        "# etapas acima, fazendo efetivamente\n",
        "# o treinamento da rede neural para\n",
        "# todos os dados de treinamento que\n",
        "# já tínhamos separado inicialmente\n",
        "\n",
        "# Laço para 1001 épocas\n",
        "\n",
        "for i in range(1001):\n",
        "\n",
        "  # Para cada par de entrada\n",
        "  # e respectiva saída desejada\n",
        "  for x, y_hat in zip(Xt,Yt):\n",
        "\n",
        "    # Corrigimos o formato do\n",
        "    # par para que cada um seja\n",
        "    # um vetor linha (que é como\n",
        "    # o PyTorch espera)\n",
        "\n",
        "    x = x.view(1,4)\n",
        "    y_hat = y.view(1,3)\n",
        "\n",
        "    # Zeramos os gradientes dos\n",
        "    # parâmetros para receberem\n",
        "    # os resultados novos\n",
        "    p.zero_grad()\n",
        "\n",
        "    # Computamos a saída calculada\n",
        "    # (caminho direto da rede neural)\n",
        "\n",
        "    y = p(x)\n",
        "\n",
        "    # Calculamos o erro entre a saída\n",
        "    # calculada e a desejada (lembrando\n",
        "    # que esse erro permite calcular\n",
        "    # o gradiente)\n",
        "    e = loss(y, y_hat.argmax(dim=1))\n",
        "\n",
        "    # Chamamos a função que computa\n",
        "    # o gradiente da função de erro\n",
        "    # para todos parâmetros da rede\n",
        "    # neural\n",
        "\n",
        "    e.backward()\n",
        "\n",
        "    # Aqui aplicamos uma correção dos\n",
        "    # parâmetros um passo de 0.1 na\n",
        "    # direção oposta ao gradiente do\n",
        "    # erro (subtraino 0.1 vezes a\n",
        "    # derivada parcial do erro em\n",
        "    # relação a cada respectivo\n",
        "    # parâmetro)\n",
        "\n",
        "    for param in p.parameters():\n",
        "      param.data -= 0.1*param.grad.data\n",
        "  \n",
        "  # Imprimimos uma vez para\n",
        "  # cada 100 amostras\n",
        "  if not (i % 100):\n",
        "    print(float(e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.009103813208639622\n",
            "7.60526381782256e-05\n",
            "3.814624506048858e-05\n",
            "2.5510462364763953e-05\n",
            "1.9073304429184645e-05\n",
            "1.537788011773955e-05\n",
            "1.2755313036905136e-05\n",
            "1.0847986231965479e-05\n",
            "9.536697689327411e-06\n",
            "8.4638240878121e-06\n",
            "7.629365427419543e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn4te14CSRJb",
        "outputId": "c477b3a7-c32c-4393-d6b7-9f3a64d6dd1a"
      },
      "source": [
        "# O código dessa célula demonstra\n",
        "# como usar um otimizador, ao invés\n",
        "# de simplesmente subtrair passo vezes\n",
        "# gradiente.\n",
        "\n",
        "# Importamos o módulo que implementa\n",
        "# os otimizadores\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# Escolhemos aqui o stochastic gradient descent\n",
        "# que é um dos otimizadores mais simples\n",
        "# que existem.\n",
        "\n",
        "optimizer = optim.SGD(p.parameters(), lr=0.1)\n",
        "\n",
        "# Esse laço aplica o otimizador acima\n",
        "# para todo dataset de treinamento,\n",
        "# repetindo o processo 10001 vezes.\n",
        "\n",
        "for i in range(10001):\n",
        "\n",
        "  # Zeramos os gradientes\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Calculamos as saídas da\n",
        "  # rede neural de uma vez,\n",
        "  # em lote, para todas entradas\n",
        "  # de treinamento.\n",
        "\n",
        "  Y = p(Xt)\n",
        "\n",
        "  # Calculamos o erro, em lote\n",
        "  e = loss(Y, Yt.argmax(dim=1))\n",
        "\n",
        "  # Fazemos a propagação reversa\n",
        "  # dos gradientes desse erro do\n",
        "  # lote\n",
        "\n",
        "  e.backward()\n",
        "\n",
        "  # Aplicamos um passo do otimizador\n",
        "  optimizer.step()\n",
        "\n",
        "  # Aqui imprimimos uma vez\n",
        "  # a cada mil épocas\n",
        "  if not (i % 1000):\n",
        "    print(float(e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1354684829711914\n",
            "0.14748774468898773\n",
            "0.08476033061742783\n",
            "0.07048087567090988\n",
            "0.06433117389678955\n",
            "0.06082615256309509\n",
            "0.05849975347518921\n",
            "0.05680329352617264\n",
            "0.05548500269651413\n",
            "0.05441270396113396\n",
            "0.05350981652736664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTTbEwQ6fLlZ"
      },
      "source": [
        "# Rodando otimização na GPU\n",
        "\n",
        "Para rodar na GPU basta mover todos os dados para a GPU e rodar novamente a célula acima para que o treinamento aconteça dessa vez na GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqH3e3apS2NH"
      },
      "source": [
        "# Cria o objeto que representa\n",
        "# a GPU usando CUDA (NVidia)\n",
        "gpu = torch.device(\"cuda:0\")\n",
        "\n",
        "# Move rede neural e dados de\n",
        "# treinamento e validação, todos\n",
        "# para a GPU\n",
        "\n",
        "p.to(gpu)\n",
        "Xt = Xt.to(gpu)\n",
        "Yt = Yt.to(gpu)\n",
        "Xv = Xv.to(gpu)\n",
        "Yv = Yv.to(gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYK6G808foFo"
      },
      "source": [
        "# Verificação dos Resultados\n",
        "\n",
        "Esse código abaixo mostra o resultado da rede neural aplicada aos dados de validação, comparando saída calculada e desejada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQsX54y3TQn1",
        "outputId": "f185264c-8269-4193-fdea-eadb7658cfd2"
      },
      "source": [
        "Y = F.softmax(p(Xv), dim=1)\n",
        "for y, y_hat in zip(Y, Yv):\n",
        "  print(y.data, y_hat.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([    0.00,     0.00,     1.00]) tensor([0., 0., 1.])\n",
            "tensor([    1.00,     0.00,     0.00]) tensor([1., 0., 0.])\n",
            "tensor([    0.00,     1.00,     0.00]) tensor([0., 1., 0.])\n",
            "tensor([    0.00,     0.01,     0.99]) tensor([0., 0., 1.])\n",
            "tensor([    1.00,     0.00,     0.00]) tensor([1., 0., 0.])\n",
            "tensor([    0.00,     0.00,     1.00]) tensor([0., 0., 1.])\n",
            "tensor([    1.00,     0.00,     0.00]) tensor([1., 0., 0.])\n",
            "tensor([    0.00,     0.15,     0.85]) tensor([0., 0., 1.])\n",
            "tensor([    0.00,     0.99,     0.01]) tensor([0., 1., 0.])\n",
            "tensor([    0.00,     0.99,     0.01]) tensor([0., 1., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}